{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e22e67",
   "metadata": {},
   "source": [
    "# Step 1: Crawler Question Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb694221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2b972f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Step 1: Crawler Question Bank Management\n",
    "# Responsible: Receiving and storing question data crawled from various travel platforms\n",
    "# ============================================================================\n",
    "@dataclass\n",
    "class TravelQuestion:\n",
    "    \"\"\"\n",
    "    Travel Question Data Class\n",
    "    Used to store question data crawled from various platforms\n",
    "    \"\"\"\n",
    "    question_id: str      # Unique question identifier\n",
    "    text: str            # Question text content\n",
    "    question_type: str   # Question type: single choice, multiple choice, open-ended\n",
    "    options: List[str]   # Option list (only for choice questions)\n",
    "    source_platform: str # Data source platform\n",
    "    original_category: str  # Original category (preliminary classification by crawler)\n",
    "\n",
    "class CrawlerQuestionBank:\n",
    "    \"\"\"\n",
    "    Crawler Question Bank Management Class\n",
    "    Main function: Store and manage question data crawled from various platforms\n",
    "    \"\"\"\n",
    "   \n",
    "    def __init__(self):\n",
    "        # Use dictionary to store all questions, key is question_id, value is TravelQuestion object\n",
    "        self.questions = {}\n",
    "        # Record all data source platforms\n",
    "        self.platforms = set()\n",
    "    \n",
    "    def add_crawled_questions(self, crawled_data: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Batch add question data obtained by crawler\n",
    "        Input: Raw data list provided by crawler team\n",
    "        Output: Processing result statistics (success count, error messages, etc.)\n",
    "        \"\"\"\n",
    "        # TODO: Data validation, deduplication, storage logic\n",
    "        # Need to check data format, remove duplicate questions, generate unique question_id\n",
    "        results = {'added_count': 0, 'errors': []}\n",
    "        return results\n",
    "    \n",
    "    def get_questions_by_platform(self, platform: str) -> List[TravelQuestion]:\n",
    "        \"\"\"\n",
    "        Filter questions by platform name\n",
    "        Example: Get all questions from Booking\n",
    "        \"\"\"\n",
    "        # TODO: Platform filtering logic\n",
    "        return []\n",
    "    \n",
    "    def get_question_count_by_platform(self) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Count number of questions by platform\n",
    "        Output example: {'Ctrip': 50, 'Booking.com': 30, ...}\n",
    "        \"\"\"\n",
    "        # TODO: Platform statistics logic\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc5d7cc",
   "metadata": {},
   "source": [
    "# Step 2: Data Integration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1e690fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Step 2: Data Integration and Preprocessing\n",
    "# Responsible: Cleaning and standardizing crawled raw data\n",
    "# ============================================================================\n",
    "\n",
    "class DataIntegrationPreprocessor:\n",
    "    \"\"\"\n",
    "    Data Integration and Preprocessing Class\n",
    "    Main function: Clean, classify, and evaluate complexity of raw data\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Travel domain keyword dictionary for automatic question classification, needs continuous improvement based on actual questionnaire content\n",
    "    def __init__(self):\n",
    "        self.travel_keywords = {\n",
    "            '住宿': 'accommodation', '酒店': 'accommodation', '民宿': 'accommodation',\n",
    "            '交通': 'transportation', '航班': 'transportation', '机票': 'transportation',\n",
    "            '火车': 'transportation', '地铁': 'transportation', '租车': 'transportation',\n",
    "            '美食': 'food', '餐厅': 'food', '小吃': 'food', '早餐': 'food',\n",
    "            '景点': 'attraction', '门票': 'attraction', '博物馆': 'attraction',\n",
    "            '签证': 'visa', '护照': 'visa', '入境': 'visa', '证件': 'visa',\n",
    "            '预算': 'budget', '价格': 'budget', '费用': 'budget', '花费': 'budget'\n",
    "        }\n",
    "    \n",
    "    # 2. Main method for data integration and cleaning\n",
    "    # Input: Raw question data\n",
    "    # Output: List of cleaned structured data\n",
    "    def integrate_and_clean(self, raw_questions: List[Any]) -> List[Dict[str, Any]]:\n",
    "        processed_questions_map = {}  # Use dictionary storage, key is question text, value is processed question\n",
    "        text_frequency = {}  # Single question occurrence frequency\n",
    "        \n",
    "        for i, raw_question in enumerate(raw_questions):\n",
    "            try:\n",
    "                # 1. Extract question text\n",
    "                question_text = self._extract_question_text(raw_question)\n",
    "                if not question_text:  # Skip empty text\n",
    "                    continue\n",
    "                \n",
    "                # 2. Text cleaning\n",
    "                cleaned_text = self._clean_text(question_text)\n",
    "                if not cleaned_text:  # Skip text that becomes empty after cleaning\n",
    "                    continue\n",
    "                \n",
    "                # 3. Count frequency (count regardless of duplication)\n",
    "                text_frequency[cleaned_text] = text_frequency.get(cleaned_text, 0) + 1\n",
    "                \n",
    "                # 4. If this question has been processed, skip duplicate processing\n",
    "                if cleaned_text in processed_questions_map:\n",
    "                    continue\n",
    "                \n",
    "                # 5. Extract and standardize options\n",
    "                raw_options = self._extract_options(raw_question)\n",
    "                standardized_options = self._standardize_options(raw_options)\n",
    "                \n",
    "                # 6. Determine question type (based on number of options)\n",
    "                question_type = self._determine_question_type(standardized_options)\n",
    "                \n",
    "                # 7. Automatic classification and complexity evaluation\n",
    "                category = self.categorize_question(cleaned_text)\n",
    "                complexity = self.calculate_complexity(cleaned_text, standardized_options, question_type)\n",
    "                \n",
    "                # 8. Build structured output (including frequency information)\n",
    "                processed_question = {\n",
    "                    'question_id': getattr(raw_question, 'question_id', f'Q{i:04d}'), # Question ID\n",
    "                    'text': cleaned_text, # Simple character processing\n",
    "                    'options': standardized_options, # Extract options\n",
    "                    'question_type': question_type, # Question type, such as single choice, multiple choice, open-ended\n",
    "                    'category': category, # Automatic classification result, such as accommodation, transportation\n",
    "                    'complexity': complexity, # Question complexity based on: text length, number of options, question type, keywords\n",
    "                    'frequency': text_frequency[cleaned_text], # Number of occurrences after cleaning\n",
    "                    'source_platform': getattr(raw_question, 'source_platform', 'unknown'),\n",
    "                    'original_category': getattr(raw_question, 'original_category', 'unknown')\n",
    "                }\n",
    "                \n",
    "                # 9. Store in dictionary (key is question text)\n",
    "                processed_questions_map[cleaned_text] = processed_question\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Skip questions that failed processing\n",
    "                continue\n",
    "        \n",
    "        # Return list of all unique questions\n",
    "        return list(processed_questions_map.values())\n",
    "    \n",
    "    # 3. Frequency statistics\n",
    "    def get_question_frequency_report(self, processed_questions: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate question frequency statistics report\"\"\"\n",
    "        if not processed_questions:\n",
    "            return {}\n",
    "        \n",
    "        frequency_report = {\n",
    "            'total_questions': len(processed_questions),\n",
    "            'unique_questions': len(set(q['text'] for q in processed_questions)),\n",
    "            'top_questions': [],\n",
    "            'frequency_distribution': {}  # Frequency distribution: how many questions appear once, twice, etc.\n",
    "        }\n",
    "        \n",
    "        # Count frequency of each question (obtained from processed_questions)\n",
    "        text_frequency = {}\n",
    "        for question in processed_questions:\n",
    "            text = question['text']\n",
    "            frequency = question.get('frequency', 1)  # Get frequency, default to 1 if not present\n",
    "            text_frequency[text] = frequency\n",
    "        \n",
    "        # Find highest frequency questions (sorted by frequency)\n",
    "        sorted_frequency = sorted(text_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "        frequency_report['top_questions'] = [\n",
    "            {'question': text, 'frequency': freq} \n",
    "            for text, freq in sorted_frequency[:10]  # Top 10 highest frequency questions\n",
    "        ]\n",
    "        \n",
    "        # Count frequency distribution\n",
    "        freq_dist = {}\n",
    "        for count in text_frequency.values():\n",
    "            freq_dist[count] = freq_dist.get(count, 0) + 1\n",
    "        frequency_report['frequency_distribution'] = freq_dist\n",
    "        \n",
    "        return frequency_report\n",
    "\n",
    "    # 4. Function support  \n",
    "    def _extract_question_text(self, raw_question: Any) -> str:\n",
    "        \"\"\"Extract question text from raw data\"\"\"\n",
    "        if hasattr(raw_question, 'text'):\n",
    "            return raw_question.text\n",
    "        elif isinstance(raw_question, dict) and 'text' in raw_question:\n",
    "            return raw_question['text']\n",
    "        return \"\"\n",
    "    \n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean question text: remove HTML tags, special characters, extra spaces\"\"\"\n",
    "        if not text: \n",
    "            return \"\"\n",
    "        # Remove HTML tags\n",
    "        cleaned = re.sub(r'<[^>]+>', '', text)\n",
    "        # Keep only Chinese, English, numbers and basic punctuation\n",
    "        cleaned = re.sub(r'[^\\w\\u4e00-\\u9fff\\s\\.\\?\\!]', ' ', cleaned)\n",
    "        # Merge multiple spaces into single space\n",
    "        cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "        return cleaned\n",
    "    \n",
    "    def _extract_options(self, raw_question: Any) -> List[str]:\n",
    "        \"\"\"Extract options from raw data\"\"\"\n",
    "        if hasattr(raw_question, 'options'):\n",
    "            return raw_question.options\n",
    "        elif isinstance(raw_question, dict) and 'options' in raw_question:\n",
    "            return raw_question['options']\n",
    "        return []\n",
    "    \n",
    "    def _standardize_options(self, options: List[str]) -> List[str]:\n",
    "        \"\"\"Standardize option format: clean whitespace, remove numbering prefixes\"\"\"\n",
    "        if not options: \n",
    "            return [\"Yes\", \"No\"]  # Default options\n",
    "        \n",
    "        standardized = []\n",
    "        for option in options:\n",
    "            if not option: \n",
    "                continue\n",
    "            # Remove numbering prefixes like \"A.\", \"1)\", etc.\n",
    "            cleaned = re.sub(r'^[A-Za-z0-9][\\.、\\)）]?\\s*', '', option.strip())\n",
    "            # Clean spaces\n",
    "            cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "            if cleaned: \n",
    "                standardized.append(cleaned)\n",
    "        \n",
    "        return standardized if standardized else [\"Yes\", \"No\"]\n",
    "    \n",
    "    def _determine_question_type(self, options: List[str]) -> str:\n",
    "        \"\"\"Determine question type based on options\"\"\"\n",
    "        count = len(options)\n",
    "        if count == 0: \n",
    "            return \"open_ended\"  # Open-ended question\n",
    "        elif count == 2 and any(opt in [\"Yes\", \"No\", \"Have\", \"Don't have\"] for opt in options): \n",
    "            return \"yes_no\"  # Yes/No question\n",
    "        elif count <= 4: \n",
    "            return \"single_choice\"  # Single choice question\n",
    "        else: \n",
    "            return \"multiple_choice\"  # Multiple choice question\n",
    "    \n",
    "    def calculate_complexity(self, text: str, options: List[str], question_type: str) -> str:\n",
    "        \"\"\"\n",
    "        Calculate question complexity\n",
    "        Based on: text length, number of options, question type, keyword difficulty\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "        \n",
    "        # Text length scoring\n",
    "        if len(text) > 60: \n",
    "            score += 3  # Long text, high complexity\n",
    "        elif len(text) > 40: \n",
    "            score += 2  # Medium text\n",
    "        elif len(text) > 20: \n",
    "            score += 1  # Short text\n",
    "        \n",
    "        # Option count scoring\n",
    "        if len(options) > 6: \n",
    "            score += 2  # Many options, high complexity\n",
    "        elif len(options) > 4: \n",
    "            score += 1  # Medium options\n",
    "        \n",
    "        # Question type scoring\n",
    "        if question_type == \"open_ended\": \n",
    "            score += 2  # Open-ended questions are more difficult\n",
    "        elif question_type == \"multiple_choice\": \n",
    "            score += 1  # Multiple choice questions are medium\n",
    "        \n",
    "        # Keyword difficulty scoring\n",
    "        hard_words = ['Visa', 'Policy', 'Planning', 'Budget', 'Compare', 'Why']\n",
    "        if any(word in text for word in hard_words): \n",
    "            score += 2  # Contains complex concepts\n",
    "        \n",
    "        # Final classification\n",
    "        if score >= 6: \n",
    "            return \"hard\"\n",
    "        elif score >= 3: \n",
    "            return \"medium\"\n",
    "        else: \n",
    "            return \"easy\"\n",
    "    \n",
    "    def categorize_question(self, text: str) -> str:\n",
    "        \"\"\"Automatically classify questions based on keywords\"\"\"\n",
    "        if not text: \n",
    "            return \"general\"\n",
    "        # Traverse keyword dictionary to find matching classification\n",
    "        for chinese, english in self.travel_keywords.items():\n",
    "            if chinese in text: \n",
    "                return english\n",
    "        return \"general\"  # Default classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b141c83f",
   "metadata": {},
   "source": [
    "# Step 3: Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d682ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Step 3: Cluster Analysis\n",
    "# Responsible: Using K-means and other algorithms to group similar questions\n",
    "# ============================================================================\n",
    "\n",
    "class QuestionClusterAnalyzer:\n",
    "    def __init__(self, n_clusters: int = 6):\n",
    "        self.n_clusters = n_clusters  # Number of clusters: defined based on data situation\n",
    "        self.is_trained = False  # Model training status\n",
    "        # TODO: Add vectorizer, clustering model, etc.\n",
    "    \n",
    "    def perform_cluster_analysis(self, processed_questions: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Execute complete cluster analysis process\n",
    "        Input: Cleaned question data\n",
    "        Output: Cluster results and statistical analysis\n",
    "        \"\"\"\n",
    "        # TODO: Specific clustering steps to implement:\n",
    "        # 1. Text vectorization (TF-IDF or Word2Vec)\n",
    "        # 2. K-means clustering algorithm\n",
    "        # 3. Cluster result analysis (silhouette score, etc.)\n",
    "        # 4. Extract keywords for each cluster\n",
    "        \n",
    "        cluster_results = {\n",
    "            'cluster_count': self.n_clusters, # Number of clusters used\n",
    "            'questions_processed': len(processed_questions), # Total number of questions processed\n",
    "            'cluster_assignments': [],  # Which cluster each question belongs to\n",
    "            'silhouette_score': 0.0,   # Cluster effectiveness score\n",
    "            'cluster_keywords': {}     # Characteristic keywords for each cluster\n",
    "        }\n",
    "        self.is_trained = True\n",
    "        return cluster_results\n",
    "    \n",
    "    def assign_cluster(self, question_text: str) -> int:\n",
    "        \"\"\"Assign new question to appropriate cluster\"\"\"\n",
    "        if not self.is_trained:\n",
    "            return 0  # Return default cluster if model not trained\n",
    "        # TODO: Use trained model to predict cluster for new question\n",
    "        return 0\n",
    "    \n",
    "    def get_cluster_keywords(self, cluster_id: int) -> List[str]:\n",
    "        \"\"\"Get characteristic keywords for specified cluster\"\"\"\n",
    "        # TODO: Analyze cluster centers, extract representative words\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949e54d1",
   "metadata": {},
   "source": [
    "# Step 4: Question Hierarchy and Recursive Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abd43c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Step 4: Question Hierarchy and Recursive Relationships\n",
    "# Responsible: Establishing logical relationship network between questions, implementing personalized questionnaires\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class QuestionNode:\n",
    "    \"\"\"\n",
    "    Question Node Class\n",
    "    Used to build hierarchical structure of questions (tree relationships)\n",
    "    \"\"\"\n",
    "    question_id: str           # Question ID\n",
    "    question_text: str         # Question text\n",
    "    cluster_id: int           # Belonging cluster\n",
    "    complexity: str           # Complexity level\n",
    "    category: str             # Question category\n",
    "    parent_id: Optional[str] = None      # Parent question ID (for building hierarchy)\n",
    "    children: List[str] = None           # Child question ID list\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Post-initialization processing: Ensure children is not None\"\"\"\n",
    "        if self.children is None:\n",
    "            self.children = []\n",
    "\n",
    "class QuestionHierarchyBuilder:\n",
    "    \"\"\"\n",
    "    Question Hierarchy Builder\n",
    "    Main function: Build logical relationship network of questions based on clustering results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cluster_analyzer: QuestionClusterAnalyzer):\n",
    "        self.cluster_analyzer = cluster_analyzer\n",
    "        self.question_nodes = {}  # Store all question nodes\n",
    "        self.cluster_hierarchies = {}  # Questions grouped by cluster\n",
    "    \n",
    "    def build_hierarchy_from_clusters(self, processed_questions: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Build question hierarchy structure based on clustering results\n",
    "        Input: Cleaned and clustered question data\n",
    "        Output: Hierarchy structure building results\n",
    "        \"\"\"\n",
    "        # TODO: Building strategies to implement:\n",
    "        # 1. Build based on clustering: Establish relationships between questions in the same cluster, e.g., all questions about \"accommodation\" grouped together\n",
    "        # 2. Build based on complexity: Simple → Medium → Complex progression, e.g., first ask simple \"Do you like traveling?\" then complex \"What is your travel budget?\"\n",
    "        # 3. Build based on categories: Horizontal relationships between related category questions, e.g., accommodation questions and transportation questions may have logical relationships\n",
    "        \n",
    "        hierarchy_results = {\n",
    "            'total_nodes': len(self.question_nodes),\n",
    "            'max_depth': 0,           # Maximum depth of hierarchy\n",
    "            'root_nodes': [],         # List of root nodes\n",
    "            'leaf_nodes': []          # List of leaf nodes\n",
    "        }\n",
    "        return hierarchy_results\n",
    "    \n",
    "    def get_next_questions(self, current_question_id: str, user_answers: Dict[str, str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Recommend next questions based on current question and user answers\n",
    "        Implement core logic of personalized questionnaire\n",
    "        \"\"\"\n",
    "        # TODO: Recommendation strategies to implement:\n",
    "        # 1. Based on child node relationships, e.g., answer \"Do you like traveling?\" as \"Yes\", then recommend child question \"What type of travel do you prefer?\"\n",
    "        # 2. Based on other questions in same cluster, e.g., user answering accommodation questions, recommend other accommodation-related questions\n",
    "        # 3. Based on analysis of user answer content, e.g., user says \"limited budget\", recommend economy-related questions\n",
    "        # 4. Based on question category associations, e.g., user answered accommodation question, recommend related transportation questions\n",
    "        \n",
    "        return []  # Return list of recommended question IDs\n",
    "    \n",
    "    def get_question_relationships(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get relationship data for all questions (for visualization)\"\"\"\n",
    "        # TODO: Extract parent-child relationships, cluster relationships, etc. for drawing relationship diagrams\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ba0e2",
   "metadata": {},
   "source": [
    "# Step 5: Personalized Survey Questionnaire Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b34f4128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Step 5: Personalized Survey Questionnaire Implementation\n",
    "# Responsible: Integrate first 4 steps, implement personalized survey questionnaire through question hierarchy relationships\n",
    "# ============================================================================\n",
    "\n",
    "class TravelSurveySystem: \n",
    "    def __init__(self):\n",
    "        # TODO: Initialize component instances from first 4 steps\n",
    "        self.crawler_bank = None\n",
    "        self.preprocessor = None\n",
    "        self.cluster_analyzer = None\n",
    "        self.hierarchy_builder = None\n",
    "        self.user_sessions = {}  # Store user session data\n",
    "    \n",
    "    def process_complete_workflow(self, crawled_data: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Execute complete workflow (Steps 1-4)\n",
    "        Input: Crawler raw data\n",
    "        Output: Processing results from each step\n",
    "        \"\"\"\n",
    "        # TODO: Complete workflow to implement:\n",
    "        # 1. Data storage (Step 1)\n",
    "        # 2. Data cleaning (Step 2)\n",
    "        # 3. Cluster analysis (Step 3)\n",
    "        # 4. Hierarchy building (Step 4)\n",
    "        \n",
    "        results = {\n",
    "            'crawl_results': {},          # Step 1 results\n",
    "            'preprocessing_results': {},   # Step 2 results\n",
    "            'cluster_results': {},         # Step 3 results\n",
    "            'hierarchy_results': {}        # Step 4 results\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def start_personalized_survey(self, user_id: str, user_profile: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Start personalized survey questionnaire\n",
    "        Input: User ID and user profile (age, travel experience, etc.)\n",
    "        Output: Session ID\n",
    "        \"\"\"\n",
    "        # TODO: Select initial questions based on user profile\n",
    "        session_id = f\"user_{user_id}\"\n",
    "        # Create user session, record answer history and current questions\n",
    "        self.user_sessions[session_id] = {\n",
    "            'user_id': user_id,\n",
    "            'profile': user_profile,\n",
    "            'answers': {},      # Answered questions and answers\n",
    "            'current_questions': []  # Current questions to answer\n",
    "        }\n",
    "        return session_id\n",
    "    \n",
    "    def submit_answer(self, session_id: str, question_id: str, answer: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Submit user answer and get next questions\n",
    "        Implement core functionality of dynamic questionnaire\n",
    "        \"\"\"\n",
    "        # TODO:\n",
    "        # 1. Record user answer\n",
    "        # 2. Recommend next questions based on hierarchy relationships\n",
    "        # 3. Update session status\n",
    "        \n",
    "        return []  # Return next question ID list\n",
    "    \n",
    "    def generate_survey_report(self, session_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate personalized survey report\"\"\"\n",
    "        # TODO: Analyze user answers, generate personalized insights and recommendations, while classifying users\n",
    "        return {}\n",
    "    \n",
    "    def get_system_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get system operation statistics\"\"\"\n",
    "        # TODO: Question bank size, user count, questionnaire completion rate, etc.\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c249d6a",
   "metadata": {},
   "source": [
    "# Step 6: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8763c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Step 6: Data Visualization\n",
    "# Responsible: Generate various charts and dashboards to display data analysis results\n",
    "# ============================================================================\n",
    "\n",
    "class DataVisualization:\n",
    "    \"\"\"\n",
    "    Data Visualization Class\n",
    "    Main function: Generate various charts to display system status and analysis results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chart_templates = {}  # Chart template configuration\n",
    "    \n",
    "    def create_cluster_visualization(self, cluster_data: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Create cluster result visualization chart\n",
    "        Display: Distribution of questions in 2D space, different clusters in different colors\n",
    "        \"\"\"\n",
    "        # TODO: Use matplotlib/seaborn to create scatter plot\n",
    "        # Display distribution of each cluster and cluster centers\n",
    "        return \"cluster_visualization.png\"  # Return chart file path\n",
    "    \n",
    "    def create_category_distribution_chart(self, category_data: Dict[str, int]) -> str:\n",
    "        \"\"\"\n",
    "        Create question category distribution chart\n",
    "        Display: Number distribution of questions across travel question categories\n",
    "        \"\"\"\n",
    "        # TODO: Create bar chart or pie chart\n",
    "        # Display number of questions in accommodation, transportation, food, etc. categories\n",
    "        return \"category_distribution.png\"\n",
    "    \n",
    "    def create_complexity_analysis_chart(self, complexity_data: Dict[str, int]) -> str:\n",
    "        \"\"\"\n",
    "        Create complexity analysis chart\n",
    "        Display: Proportion distribution of easy, medium, hard questions\n",
    "        \"\"\"\n",
    "        # TODO: Create stacked bar chart or donut chart\n",
    "        return \"complexity_analysis.png\"\n",
    "    \n",
    "    def create_platform_comparison_chart(self, platform_data: Dict[str, int]) -> str:\n",
    "        \"\"\"\n",
    "        Create platform data comparison chart\n",
    "        Display: Comparison of question quantity and quality across different travel platforms\n",
    "        \"\"\"\n",
    "        # TODO: Create multi-series bar chart\n",
    "        # Compare data characteristics of Ctrip, Booking.com, etc. platforms\n",
    "        return \"platform_comparison.png\"\n",
    "    \n",
    "    def create_survey_progress_dashboard(self, survey_data: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Create survey progress dashboard\n",
    "        Display: Questionnaire completion status, user participation, etc.\n",
    "        \"\"\"\n",
    "        # TODO: Create comprehensive dashboard\n",
    "        return \"survey_dashboard.html\"\n",
    "    \n",
    "    def create_question_relationship_graph(self, relationship_data: List[Dict]) -> str:\n",
    "        \"\"\"\n",
    "        Create question relationship network graph\n",
    "        Display: Hierarchical relationships and association networks between questions\n",
    "        \"\"\"\n",
    "        # TODO: Use networkx to create network graph\n",
    "        # Nodes represent questions, edges represent association relationships\n",
    "        return \"question_relationship.png\"\n",
    "    \n",
    "    def create_user_analysis_report(self, user_data: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Create personalized analysis report for individual user\n",
    "        Input: User data, including user profile, answer records, classification results, dimension scores, etc.\n",
    "        Output: Visualization (such as html)\n",
    "        \"\"\"\n",
    "        # TODO: Report content: User type, classification basis (key answers), feature radar chart (displaying user scores across multiple dimensions), personalized travel recommendations (destinations, activities, budget, etc.) implement detailed analysis (such as html implementation), mainly including overall user behavior analysis, preference insights, and feedback after individual user completes all questions (user type and personalized recommendations)\n",
    "        return \"user_analysis_report.html\"\n",
    "    \n",
    "    def create_allusers_analysis_report(self, system_data: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate overall user analysis report\n",
    "           Total users, classification status, completion rate, etc.\n",
    "        \"\"\"\n",
    "        return \"allusers_analysis_report.html\"  \n",
    "    \n",
    "    def export_all_visualizations(self, system_data: Dict[str, Any]) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Export all visualization charts\n",
    "        Input: Data from various system modules\n",
    "        Output: Dictionary of paths to various chart files\n",
    "        \"\"\"\n",
    "        visualizations = {\n",
    "            'clusters': self.create_cluster_visualization(system_data.get('cluster_data', {})),\n",
    "            'categories': self.create_category_distribution_chart(system_data.get('category_data', {})),\n",
    "            'complexity': self.create_complexity_analysis_chart(system_data.get('complexity_data', {})),\n",
    "            'platforms': self.create_platform_comparison_chart(system_data.get('platform_data', {})),\n",
    "            'survey_dashboard': self.create_survey_progress_dashboard(system_data.get('survey_data', {})),\n",
    "            'relationships': self.create_question_relationship_graph(system_data.get('relationship_data', [])),\n",
    "            'individual_user_report': self.create_user_analysis_report(system_data.get('user_data', {})),\n",
    "            'all_users_report': self.create_allusers_analysis_report(system_data.get('system_stats', {}))\n",
    "        }\n",
    "        return visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f5a10",
   "metadata": {},
   "source": [
    "# Step 7: Main Program Library Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d00dc298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Main Program Library Integration\n",
    "# Responsible: Integrate all components from 6 steps, provide unified interface\n",
    "# ============================================================================\n",
    "\n",
    "class TravelSurveyLibrary:\n",
    "# Travel Survey Questionnaire Program Library\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Step 1: Crawler Question Bank\n",
    "        self.crawler_bank = CrawlerQuestionBank()\n",
    "        \n",
    "        # Step 2: Data Integration and Preprocessing\n",
    "        self.data_preprocessor = DataIntegrationPreprocessor()\n",
    "        \n",
    "        # Step 3: Cluster Analysis\n",
    "        self.cluster_analyzer = QuestionClusterAnalyzer(n_clusters=6)\n",
    "        \n",
    "        # Step 4: Question Hierarchy and Recursive Relationships\n",
    "        self.hierarchy_builder = QuestionHierarchyBuilder(self.cluster_analyzer)\n",
    "        \n",
    "        # Step 5: Personalized Survey Questionnaire Implementation\n",
    "        self.survey_system = TravelSurveySystem()\n",
    "        \n",
    "        # Step 6: Data Visualization\n",
    "        self.visualization = DataVisualization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
